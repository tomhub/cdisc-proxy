# ğŸš€ CDISC Library API Proxy

> A fast, **extremely opinionated**, mildly unhinged (by design) caching proxy for the **CDISC Library API**.
>
> Built in Go. Tuned for production. Designed to survive real-world CDISC outages without flapping, stampeding, or waking you up at 03:00 because *someone reran the pipeline*.
>
> Yes, it caches errors.  
> No, thatâ€™s not a bug.  
> Yes, weâ€™ve thought about it more than you have.

---

## ğŸ˜ˆ What This Thing Does (And Why Youâ€™re Already Late to the Party)

Letâ€™s establish some uncomfortable truths[citation required]:

- You do **not** control the CDISC Library API  
- It will be slow, eventually  
- It will be down, occasionally  
- Your pipelines will react like toddlers on espresso  

So this proxy exists to sit in the middle, arms crossed, and say:

> â€œAbsolutely not. You will not all panic at once.â€

### In one breath (because youâ€™re busy):

- **Always caches** (even non-200 responses, briefly, on purpose)
- **Two-tier cache**
  - âš¡ L1 RAM cache (Valkey / Redis / Dragonfly)
  - ğŸ—„ï¸ L2 persistent cache (BadgerDB or PostgreSQL)
- **Singleflight deduplication** â€” one upstream call, everyone else waits
- **Streaming leader / cached followers**
- **Namespace-aware invalidation** via `/mdr/lastupdated`
- **Health checks that donâ€™t scream** because CDISC sneezed

If youâ€™ve ever watched a CI pipeline accidentally DDoS CDISCâ€¦  
congratulations, this proxy is your emotional support mammal.

---

## ğŸ§  Big Picture (AKA â€œWhere the Panic Is Containedâ€)

```
Client
  â”‚
  â–¼
ğŸ§  CDISC Proxy (this repo)
  â”‚
  â”œâ”€ âš¡ L1 Cache (Valkey / Redis / Dragonfly)
  â”‚    â””â”€ tiny, hot, easily offended
  â”‚
  â”œâ”€ ğŸ¦¡ L2 Cache (BadgerDB or PostgreSQL)
  â”‚    â””â”€ durable, grumpy, hoards metadata forever
  â”‚
  â””â”€ ğŸŒ CDISC Library API
       â””â”€ singleflight protected (no stampedes, riots, or regrets)
```

Think of this as a shock absorber.  
Or a bouncer.  
Or a racoon guarding a dumpster full of cached metadata.

---

## ğŸï¸ The Life of a Request (No Fairy Tales)

1. **L1 lookup** â€” hit? instant response.
2. **L2 lookup** â€” hit? served from disk. Small enough? Copy self to L1.
3. **Upstream call (singleflight)** â€” one request, many followers.

No thundering herds.  
No duplicate CDISC calls.  
No surprise retrospectives.

---

## ğŸ§Š Cache Keys (Yes, We Thought About This)

```
cdisc:cache:<namespace>:<request-uri>
```

Status codes survive caching:

```json
{ "s": 404, "b": "{ \"error\": \"Not Found\" }" }
```

No fake 200s. No lies.

---

## ğŸ˜ˆ Negative Caching

Non-200 responses are cached for 5 minutes:

```go
negativeCacheTTL = 5 * time.Minute
```

Outages become boring.  
Boring is good.

---

## ğŸ§­ Namespace-Aware Invalidation

Uses `/mdr/lastupdated`.

Flush only what changed.  
Not the universe.

---

## ğŸ¤¡ Why Not Just Use NGINX?

You can.

NGINX is a **dumb fridge**.  
This proxy is a **judgmental racoon**.

NGINX canâ€™t:
- Deduplicate upstream calls
- Invalidate by CDISC namespace
- Avoid stampedes
- Understand CDISC semantics

---

## ğŸ¤¡ Why Not Varnish?

Varnish is excellent at:
- Being fast
- Being stateless
- Being *your problem at 02:00*

It still:
- Has no idea what SDTM is
- Canâ€™t read `/mdr/lastupdated`
- Will happily serve stale-but-fast lies
- Requires ritual VCL sacrifices

---

## ğŸ“– A True Story (Postmortem Edition, LLM Hallucination) [not true story]

**02:17 UTC**  
CDISC slows down.

**02:18 UTC**  
CI pipelines notice.

**02:19 UTC**  
400 identical requests hit `/mdr/sdtm`.

**02:20 UTC**  
NGINX shrugs.

**02:21 UTC**  
CDISC rate-limits you.

**02:22 UTC**  
Slack explodes.

With this proxy:
- First request goes out
- Others wait
- Cache fills
- Everyone goes back to sleep

---

## ğŸ“œ License

MIT. Do what you want. Just donâ€™t pretend you werenâ€™t warned.

---

<div align="center">
ğŸ¦¡ Powered by Badgers. ğŸ¦ Guarded by Racoons. Deployed by Enthusiasts. Made with â¤ï¸ for the clinical research community.
</div>
